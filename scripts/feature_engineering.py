# -*- coding: utf-8 -*-
"""Feature_Engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q3BXQzcnEksSNAwarh7w1ZmOLWEZDgL_

### *Problem we are solving : To explore advanced hybrid model frameworks that can resist adversarial phishing websites crafted using Generative Adversarial Networks (GANs). This research will focus on improving robustness through adversarial training combined with multi-modal feature extraction (e.g., URL, HTML content, metadata).*

### **Feature Extraction from URLs:**

**1. Address Bar-Based Features :**
In this step, we extract specific features from the URLs that provide important information about the structure and behavior of the URL. These features fall under the category of "Address Bar-Based Features" and are derived from the components of the URL. The following features are particularly relevant to understanding potential malicious URLs:

* Domain of the URL :
The domain name is a critical component in identifying the origin of the URL. Extracting the domain allows us to analyze whether the domain is known or suspicious. This can help in detecting phishing attacks where malicious domains are used.

* IP Address in the URL :
URLs that directly contain an IP address, instead of a domain name, can indicate suspicious behavior. In many legitimate websites, domains are used instead of raw IP addresses, so detecting IP addresses can be a red flag for phishing or other malicious activities.

* Presence of "@" Symbol in the URL :
The @ symbol in URLs is commonly used in email addresses and is sometimes seen in suspicious URLs. Phishing sites may use this symbol to hide part of the domain or mislead users into clicking the URL.

* Length of the URL :
The length of a URL can be indicative of its nature. Malicious URLs are often longer due to the use of obfuscation techniques, which may include random strings or misleading parameters.

* Depth of the URL :
The depth of the URL refers to the number of subdirectories or folders in the path of the URL. A higher depth could indicate an unusual or suspicious structure, which is often seen in phishing or malicious sites designed to mimic legitimate websites.

* Redirection "//" in the URL :
URLs with multiple consecutive slashes (e.g., //) after the domain part may indicate a redirection or an attempt to obscure the true destination. Phishing sites sometimes use this technique to disguise their real nature.

* HTTP/HTTPS in the Domain Name :
URLs that contain http or https in the domain name (e.g., examplehttp.com) can indicate a misrepresentation of a legitimate website. Such URLs attempt to mimic well-known and trusted domains by inserting these protocols into the domain part.

* Use of URL Shortening Services (e.g., TinyURL) :
URLs shortened by services like TinyURL are commonly used to mask the original destination. While they can be used for legitimate purposes, they are also often associated with phishing attacks where the attacker hides the true URL destination to deceive users.

* Prefix or Suffix "-" in the Domain :
The presence of hyphens (-) in domain names can be indicative of attempts to mimic legitimate domain names by inserting these characters in specific positions. For example, phishing sites may use a hyphen in an attempt to look like a well-known brand.

Each of these features can be extracted from the URL and used to assess the likelihood of a URL being malicious. By examining these attributes, we can build a set of features that can help in classifying URLs as legitimate or phishing. The next step involves coding these features to automatically extract them from a given set of URLs.
"""

!pip install python-whois

!pip install dnspython

# importing required packages for this section
from urllib.parse import urlparse,urlencode
import ipaddress
import re

from bs4 import BeautifulSoup
import whois
import urllib
import urllib.request
from datetime import datetime

import requests
from urllib3.exceptions import MaxRetryError, NameResolutionError
from requests.exceptions import ConnectionError

"""Domain of the URL"""

def getDomain(url):
    domain = urlparse(url).netloc
    if re.match(r"^www.",domain):
        domain = domain.replace("www.","")
    return domain

"""IP Address in the URL"""

def haveIP(url):
    try:
        ipaddress.ip_address(url)
        ip = 1
    except:
        ip = 0
    return ip

""""@" Symbol in URL"""

def haveAt(url):
    if "@" in url:
        at = 1
    else:
        at = 0
    return at

"""Length of the URL"""

def getLength(url):
    if len(url) < 60:
        length = 0
    else:
        length = 1
    return length

"""Depth of URL"""

def getDepth(url):
    s = urlparse(url).path.split('/')
    depth = 0
    for j in range(len(s)):
        if len(s[j]) != 0:
            depth = depth + 1
    return depth

"""Redirection "//" in URL"""

def redirection(url):
    pos = url.rfind('//')
    if pos > 6: #checks for http
        if pos > 1: #checks for https
            return 1 # denotes phishing
        else:
            return 0
    else:
        return 0
        # indicates legitimate

""""http/https"in Domain name"""

def httpDomain(url):
    domain = urlparse(url).netloc
    if 'https' in domain:
        return 1 # returns phishing
    else:
        return 0 # return legit

"""Using URL Shortening Services “TinyURL”"""

#listing shortening services
shortening_services = r"bit\.ly|goo\.gl|shorte\.st|go2l\.ink|x\.co|ow\.ly|t\.co|tinyurl|tr\.im|is\.gd|cli\.gs|" \
                      r"yfrog\.com|migre\.me|ff\.im|tiny\.cc|url4\.eu|twit\.ac|su\.pr|twurl\.nl|snipurl\.com|" \
                      r"short\.to|BudURL\.com|ping\.fm|post\.ly|Just\.as|bkite\.com|snipr\.com|fic\.kr|loopt\.us|" \
                      r"doiop\.com|short\.ie|kl\.am|wp\.me|rubyurl\.com|om\.ly|to\.ly|bit\.do|t\.co|lnkd\.in|db\.tt|" \
                      r"qr\.ae|adf\.ly|goo\.gl|bitly\.com|cur\.lv|tinyurl\.com|ow\.ly|bit\.ly|ity\.im|q\.gs|is\.gd|" \
                      r"po\.st|bc\.vc|twitthis\.com|u\.to|j\.mp|buzurl\.com|cutt\.us|u\.bb|yourls\.org|x\.co|" \
                      r"prettylinkpro\.com|scrnch\.me|filoops\.info|vzturl\.com|qr\.net|1url\.com|tweez\.me|v\.gd|" \
                      r"tr\.im|link\.zip\.net"

def tinyURL(url):
    matches = re.search(shortening_services,url)
    if matches:
        return 1 #phishing
    else:
        return 0 #legitimate

"""Prefix or Suffix "-" in Domain"""

def prefixSuffix(url):
    if '-' in urlparse(url).netloc:
        return 1 #phishing
    else:
        return 0 #legitimate

"""### **Domain-Based Features for URL Analysis**
When analyzing URLs for phishing detection or classification, domain-based features play a critical role in identifying suspicious patterns. Some of the features that can be extracted from a domain include:

* DNS Record: This feature checks whether the domain has a valid DNS (Domain Name System) record. Phishing sites may not have valid DNS records, as they may be temporary or fake domains.

* Age of Domain: The age of the domain can be an important factor. Legitimate websites typically have older domains, while phishing websites may often use newly registered domains to evade detection.

* End Period of Domain: This feature checks the expiration date of a domain. Phishing websites often use domains that are either set to expire soon or are very new, while legitimate websites have longer expiration periods.

Each of these features can be implemented using Python, often with the help of external libraries or APIs to fetch domain information.
"""

import dns.resolver

import whois
import socket
from urllib.parse import urlparse

def check_dns_records(url):
    try:
        # Extract the domain from the URL
        domain = urlparse(url).netloc

        # Perform DNS resolution (optional, for early detection of invalid domains)
        socket.gethostbyname(domain)

        # Perform WHOIS query
        domain_info = whois.whois(domain)

        return 0  # Return 0 for legitimate domains

    except socket.gaierror as e:
        return 1

    except socket.timeout as e:

        return 1

    except whois.parser.PywhoisError as e:

        return 1

    except Exception as e:
        return 1

"""Age of Domain"""

from datetime import datetime
from urllib.parse import urlparse

def domainAge(url):
    domain_name = urlparse(url).netloc
    try:
        domain_info = whois.whois(domain_name)
    except whois.parser.PywhoisError:
        return 1  # Treat missing WHOIS as suspicious

    if domain_info is None:
        return 1  # Invalid WHOIS data or DNS resolution failure (suspicious)

    creation_date = domain_info.creation_date
    expiration_date = domain_info.expiration_date

    # Handle cases where dates are not available or are lists
    if creation_date is None or expiration_date is None:
        return 1  # If dates are missing, it's suspicious

    # If dates are lists, take the first element
    if isinstance(creation_date, list):
        creation_date = creation_date[0]
    if isinstance(expiration_date, list):
        expiration_date = expiration_date[0]

    # If dates are strings, parse them
    if isinstance(creation_date, str):
        try:
            creation_date = datetime.strptime(creation_date, '%Y-%m-%d')
        except ValueError:
            return 1  # Error parsing date (suspicious)

    if isinstance(expiration_date, str):
        try:
            expiration_date = datetime.strptime(expiration_date, '%Y-%m-%d')
        except ValueError:
            return 1  # Error parsing date (suspicious)

    # Calculate domain age
    today = datetime.now()
    age_in_days = (expiration_date - creation_date).days

    # If domain age is less than 6 months (180 days), it's considered suspicious
    if age_in_days < 180:
        return 1  # Domain is less than 6 months old (suspicious)

    return 0  # Domain is legitimate

"""End Period of Domain"""

from datetime import datetime
from urllib.parse import urlparse

def domainEnd(url):
    domain_name = urlparse(url).netloc
    try:
        domain_info = whois.whois(domain_name)
    except whois.parser.PywhoisError:
        return 1  # Treat missing WHOIS as suspicious

    # ... rest of your function (from line 7 onwards) ...
    if domain_info is None:
        return 1  # Invalid WHOIS data or DNS resolution failure (suspicious)

    expiration_date = domain_info.expiration_date

    if expiration_date is None:
        return 1  # No expiration date found, treat as suspicious

    # If expiration_date is a list, take the first element
    if isinstance(expiration_date, list):
        expiration_date = expiration_date[0]

    # Handle string dates and convert to datetime
    if isinstance(expiration_date, str):
        try:
            expiration_date = datetime.strptime(expiration_date, "%Y-%m-%d")
        except ValueError:
            return 1  # Error parsing date (suspicious)

    # If expiration_date is still not a datetime object, return 1 (suspicious)
    if not isinstance(expiration_date, datetime):
        return 1  # Invalid expiration date format (suspicious)

    # Calculate remaining days until expiration
    today = datetime.now()
    remaining_days = (expiration_date - today).days

    if remaining_days <= 0:
        return 1  # Domain expired (suspicious)

    remaining_months = remaining_days / 30  # Convert days to months
    if remaining_months < 6:
        return 1  # Less than 6 months remaining (suspicious)

    return 0  # Domain is legitimate

"""## **HTML and JavaScript-based Features**

Phishing websites often manipulate the HTML and JavaScript code of a webpage to deceive users. Below are some key features that can be used to identify phishing websites:

 * **IFrame Redirection**  
   Phishing websites may use hidden or invisible IFrames to redirect users to malicious sites. IFrames can be used to load a fake page or capture user credentials without their knowledge.

*  **Status Bar Customization**  
   Phishers may alter the status bar in a web browser using JavaScript to trick users into thinking they are interacting with a legitimate website. This feature is commonly used to make suspicious links appear safe.

* **Disabling Right Click**  
   Some phishing sites disable the right-click functionality to prevent users from inspecting the page, viewing source code, or accessing other browser tools that could reveal malicious activity.

* **Website Forwarding**  
   Phishing sites may automatically redirect users to another webpage, often a fake login page, to capture sensitive information. This forwarding is usually achieved using JavaScript or HTML meta-refresh tags.

These features are often indicators of a phishing attempt, and identifying them can help flag suspicious websites.

*IFrame Redirection*
"""

def iframe(response):
    if response == "":
        return 1
    else:
        if re.findall(r"[|]", response.text):
            return 0
        else:
            return 1

"""Status Bar Customization"""

def mouseOver(response):
  if response == "" :
    return 1
  else:
    if re.findall("", response.text):
      return 1
    else:
      return 0

"""Disabling Right Click"""

def rightClick(response):
  if response == "":
    return 1
  else:
    if re.findall(r"event.button ?== ?2", response.text):
      return 0
    else:
      return 1

"""Website Forwarding"""

def forwarding(response):
  if response == "":
    return 1
  else:
    if len(response.history) <= 2:
      return 0
    else:
      return 1

"""Calling the function to combine all the extracted features into a single dataset."""

def featureExtraction(url,label):

  features = []
  #Address bar based features (9)
  features.append(getDomain(url))
  features.append(haveIP(url))
  features.append(haveAt(url))
  features.append(getLength(url))
  features.append(getDepth(url))
  features.append(redirection(url))
  features.append(httpDomain(url))
  features.append(tinyURL(url))
  features.append(prefixSuffix(url))
  #Domain name system based features (3)
  features.append(check_dns_records(url))
  features.append(domainAge(url))
  features.append(domainEnd(url))

  response = make_request(url)
  #Domain based features (4)
  features.append(iframe(response))
  features.append(mouseOver(response))
  features.append(rightClick(response))
  features.append(forwarding(response))
  features.append(label)

  return features

feature_names = ['Domain', 'Have_IP', 'Have_At', 'URL_Length', 'URL_Depth','Redirection',
                'https_Domain', 'TinyURL', 'Prefix/Suffix', 'DNS_Record', 'Domain_Age',
                'Domain_End', 'iFrame', 'Mouse_Over','Right_Click', 'Web_Forwards', 'Label']